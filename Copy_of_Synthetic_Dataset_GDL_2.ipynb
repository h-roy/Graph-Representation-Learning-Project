{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGsDtb0lyAW"
      },
      "source": [
        "##Graph Convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zcCyWqOAu8c",
        "outputId": "bb14ae67-2f1e-4da2-c7aa-c1a8754b4a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 8.0 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 69.8 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 28.5 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (709 kB)\n",
            "\u001b[K     |████████████████████████████████| 709 kB 17.6 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=fa3fb383e2419639339467c0528d46742aaf45b914b7b8d930a5e925e3fe3b6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0 torch-geometric-2.1.0.post1 torch-scatter-2.0.9 torch-sparse-0.6.15 torch-spline-conv-1.2.1\n"
          ]
        }
      ],
      "source": [
        "%pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
        "\n",
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "\n",
        "from torch_geometric.utils import erdos_renyi_graph\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.data import Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_QP8bzUJIDN"
      },
      "outputs": [],
      "source": [
        "def get_edges(n_nodes):\n",
        "    rows, cols = [], []\n",
        "    for i in range(n_nodes):\n",
        "        for j in range(n_nodes):\n",
        "            if i != j:\n",
        "                rows.append(i)\n",
        "                cols.append(j)\n",
        "\n",
        "    edges = [rows, cols]\n",
        "    return edges\n",
        "    \n",
        "def get_edges_batch(n_nodes, batch_size):\n",
        "    edges = get_edges(n_nodes)\n",
        "    edge_attr = torch.ones(len(edges[0]) * batch_size, 1)\n",
        "    edges = [torch.LongTensor(edges[0]), torch.LongTensor(edges[1])]\n",
        "    if batch_size == 1:\n",
        "        return edges, edge_attr\n",
        "    elif batch_size > 1:\n",
        "        rows, cols = [], []\n",
        "        for i in range(batch_size):\n",
        "            rows.append(edges[0] + n_nodes * i)\n",
        "            cols.append(edges[1] + n_nodes * i)\n",
        "        edges = [torch.cat(rows), torch.cat(cols)]\n",
        "    return edges, edge_attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieGOORrWl4DU"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\" a simple 4-layer MLP \"\"\"\n",
        "\n",
        "    def __init__(self, nin, nout, nh):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(nin, nh),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(nh, nh),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(nh, nh),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(nh, nout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class GCL_basic(nn.Module):\n",
        "    \"\"\"Graph Neural Net with global state and fixed number of nodes per graph.\n",
        "    Args:\n",
        "          hidden_dim: Number of hidden units.\n",
        "          num_nodes: Maximum number of nodes (for self-attentive pooling).\n",
        "          global_agg: Global aggregation function ('attn' or 'sum').\n",
        "          temp: Softmax temperature.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GCL_basic, self).__init__()\n",
        "\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr):\n",
        "        pass\n",
        "\n",
        "    def node_model(self, h, edge_index, edge_attr):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, edge_index, edge_mask, edge_attr=None, node_attr=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat = self.edge_model(x[row], x[col], edge_attr)\n",
        "        edge_feat = edge_feat * edge_mask\n",
        "        #print(x.shape)\n",
        "        #print(node_attr.shape)\n",
        "\n",
        "        x = self.node_model(x, edge_index, edge_feat, node_attr)\n",
        "        return x, edge_feat\n",
        "\n",
        "class GCL(GCL_basic):\n",
        "    \"\"\"Graph Neural Net with global state and fixed number of nodes per graph.\n",
        "    Args:\n",
        "          hidden_dim: Number of hidden units.\n",
        "          num_nodes: Maximum number of nodes (for self-attentive pooling).\n",
        "          global_agg: Global aggregation function ('attn' or 'sum').\n",
        "          temp: Softmax temperature.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, nodes_att_dim=0,  edges_in_nf=0, act_fn=nn.ReLU(), bias=True, attention=False, t_eq=False, recurrent=True):\n",
        "        super(GCL, self).__init__()\n",
        "        self.attention = attention\n",
        "        self.t_eq=t_eq\n",
        "        self.recurrent = recurrent\n",
        "        input_edge_nf = input_nf * 2\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge_nf + edges_in_nf, hidden_nf, bias=bias),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf, bias=bias),\n",
        "            act_fn)\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(input_nf, hidden_nf, bias=bias),\n",
        "                act_fn,\n",
        "                nn.Linear(hidden_nf, 1, bias=bias),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf, bias=bias),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf, bias=bias))\n",
        "\n",
        "        #if recurrent:\n",
        "            #self.gru = nn.GRUCell(hidden_nf, hidden_nf)\n",
        "\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr):\n",
        "        edge_in = torch.cat([source, target], dim=1)\n",
        "        if edge_attr is not None:\n",
        "            edge_in = torch.cat([edge_in, edge_attr], dim=1)\n",
        "        out = self.edge_mlp(edge_in)\n",
        "        if self.attention:\n",
        "            att = self.att_mlp(torch.abs(source - target))\n",
        "            out = out * att\n",
        "        return out\n",
        "\n",
        "    def node_model(self, h, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=h.size(0))\n",
        "        if node_attr is not None:\n",
        "            out = torch.cat([h, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([h, agg], dim=1)\n",
        "\n",
        "        out = self.node_mlp(out)\n",
        "        if self.recurrent:\n",
        "            out = out + h\n",
        "            #out = self.gru(out, h)\n",
        "        return out\n",
        "\n",
        "\n",
        "def unsorted_segment_sum(data, segment_ids, num_segments):\n",
        "    \"\"\"Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`.\"\"\"\n",
        "    result_shape = (num_segments, data.size(1))\n",
        "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
        "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
        "    result.scatter_add_(0, segment_ids, data)\n",
        "    return result\n",
        "\n",
        "\n",
        "def unsorted_segment_mean(data, segment_ids, num_segments):\n",
        "    result_shape = (num_segments, data.size(1))\n",
        "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
        "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
        "    count = data.new_full(result_shape, 0)\n",
        "    result.scatter_add_(0, segment_ids, data)\n",
        "    count.scatter_add_(0, segment_ids, torch.ones_like(data))\n",
        "    return result / count.clamp(min=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_MZ1Sh9C10u"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_edge_mask(batch_size, num_nodes, nodes_list, batch_edge_index):\n",
        "  n = num_nodes\n",
        "  edge_mask = [0] * n * (n-1) * batch_size\n",
        "  for b in range(batch_size):\n",
        "    for i in nodes_list:\n",
        "      for j in nodes_list:\n",
        "        for k in  range(batch_edge_index[b].shape[1]):\n",
        "          if i == int(batch_edge_index[b][0,k]) and j == int(batch_edge_index[b][1,k]):\n",
        "            if j < i:\n",
        "              edge_mask[b * n * (n-1) + i*(n - 1) + j] = 1\n",
        "            if j > i:\n",
        "              edge_mask[b * n * (n-1) + i*(n - 1) + j - 1] = 1\n",
        "  return edge_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34tlGIHHVK7h"
      },
      "outputs": [],
      "source": [
        "def get_graph_batch(batch_size, n_nodes, p):\n",
        "  nodes_list = list(range(n_nodes))\n",
        "  \n",
        "  edges, edge_attr = get_edges_batch(n_nodes, batch_size)\n",
        "  batch_edge_index = []\n",
        "  adj_list = []\n",
        "  for i in range(batch_size):\n",
        "    edge_index = erdos_renyi_graph(n_nodes,p)\n",
        "    batch_edge_index.append(edge_index)\n",
        "    x = torch.tensor([[1]]*n_nodes, dtype=torch.float)\n",
        "    data = Data(x=x, edge_index=edge_index.contiguous())\n",
        "    G = to_networkx(data)\n",
        "    adj = np.array(nx.linalg.graphmatrix.adjacency_matrix(G).todense())\n",
        "    adj_list.append(adj)\n",
        "  edge_mask = generate_edge_mask(batch_size, n_nodes, nodes_list, batch_edge_index)\n",
        "  tensor_edge_mask = torch.tensor(edge_mask, dtype=torch.float32).reshape(-1,1)\n",
        "  return edges, edge_attr, tensor_edge_mask, adj_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM-jJYknnE_p"
      },
      "outputs": [],
      "source": [
        "input_nf, output_nf, hidden_nf, coords = 5, 1, 24, 3\n",
        "\n",
        "gcl_layer = GCL(input_nf + coords, output_nf, hidden_nf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1q615bmnLEJ"
      },
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "n_nodes = 6\n",
        "p = 0.5\n",
        "coord_dim = 3\n",
        "edges, edge_attr, tensor_edge_mask,adj_list = get_graph_batch(batch_size, n_nodes, p)\n",
        "feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "coord = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "x = torch.cat([feat, coord], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeFXOrABnvOr"
      },
      "outputs": [],
      "source": [
        "h, edge_feat = gcl_layer(x = x, edge_index = edges, edge_mask = tensor_edge_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8cR7pNcy8T0",
        "outputId": "39cf2d04-eabe-4222-a435-c573e87f18bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "h.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h65MH7-0maSV"
      },
      "source": [
        "###Overfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "fPm4e753mdod",
        "outputId": "9f0d811e-aa05-4a5a-e9a2-78da23fe935d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, MSE: 1.8206\n",
            "Epoch: 51, MSE: 1.5767\n",
            "Epoch: 101, MSE: 1.2617\n",
            "Epoch: 151, MSE: 0.8207\n",
            "Epoch: 201, MSE: 0.5755\n",
            "Epoch: 251, MSE: 0.8903\n",
            "Epoch: 301, MSE: 0.7147\n",
            "Epoch: 351, MSE: 0.5896\n",
            "Epoch: 401, MSE: 0.4579\n",
            "Epoch: 451, MSE: 0.4805\n",
            "Epoch: 501, MSE: 0.4784\n",
            "Epoch: 551, MSE: 0.5015\n",
            "Epoch: 601, MSE: 0.3787\n",
            "Epoch: 651, MSE: 0.3392\n",
            "Epoch: 701, MSE: 0.3768\n",
            "Epoch: 751, MSE: 0.4004\n",
            "Epoch: 801, MSE: 0.4146\n",
            "Epoch: 851, MSE: 0.3529\n",
            "Epoch: 901, MSE: 0.2795\n",
            "Epoch: 951, MSE: 0.2358\n",
            "Epoch: 1001, MSE: 0.2520\n",
            "Epoch: 1051, MSE: 0.2597\n",
            "Epoch: 1101, MSE: 0.2340\n",
            "Epoch: 1151, MSE: 0.2291\n",
            "Epoch: 1201, MSE: 0.2492\n",
            "Epoch: 1251, MSE: 0.2647\n",
            "Epoch: 1301, MSE: 0.2604\n",
            "Epoch: 1351, MSE: 0.2386\n",
            "Epoch: 1401, MSE: 0.2294\n",
            "Epoch: 1451, MSE: 0.2556\n",
            "Epoch: 1501, MSE: 0.2822\n",
            "Epoch: 1551, MSE: 0.2242\n",
            "Epoch: 1601, MSE: 0.2366\n",
            "Epoch: 1651, MSE: 0.2711\n",
            "Epoch: 1701, MSE: 0.2854\n",
            "Epoch: 1751, MSE: 0.2642\n",
            "Epoch: 1801, MSE: 0.2211\n",
            "Epoch: 1851, MSE: 0.2362\n",
            "Epoch: 1901, MSE: 0.3120\n",
            "Epoch: 1951, MSE: 0.2467\n",
            "Epoch: 2001, MSE: 0.2247\n",
            "Epoch: 2051, MSE: 0.2900\n",
            "Epoch: 2101, MSE: 0.3378\n",
            "Epoch: 2151, MSE: 0.3322\n",
            "Epoch: 2201, MSE: 0.2858\n",
            "Epoch: 2251, MSE: 0.2179\n",
            "Epoch: 2301, MSE: 0.2916\n",
            "Epoch: 2351, MSE: 0.3742\n",
            "Epoch: 2401, MSE: 0.3080\n",
            "Epoch: 2451, MSE: 0.2192\n",
            "Epoch: 2501, MSE: 0.3017\n",
            "Epoch: 2551, MSE: 0.3820\n",
            "Epoch: 2601, MSE: 0.4185\n",
            "Epoch: 2651, MSE: 0.3826\n",
            "Epoch: 2701, MSE: 0.3043\n",
            "Epoch: 2751, MSE: 0.2143\n",
            "Epoch: 2801, MSE: 0.3422\n",
            "Epoch: 2851, MSE: 0.4571\n",
            "Epoch: 2901, MSE: 0.4197\n",
            "Epoch: 2951, MSE: 0.2468\n",
            "Epoch: 3001, MSE: 0.2622\n",
            "Epoch: 3051, MSE: 0.3772\n",
            "Epoch: 3101, MSE: 0.4756\n",
            "Epoch: 3151, MSE: 0.4999\n",
            "Epoch: 3201, MSE: 0.4419\n",
            "Epoch: 3251, MSE: 0.3246\n",
            "Epoch: 3301, MSE: 0.2313\n",
            "Epoch: 3351, MSE: 0.3305\n",
            "Epoch: 3401, MSE: 0.4983\n",
            "Epoch: 3451, MSE: 0.5390\n",
            "Epoch: 3501, MSE: 0.4446\n",
            "Epoch: 3551, MSE: 0.2554\n",
            "Epoch: 3601, MSE: 0.2774\n",
            "Epoch: 3651, MSE: 0.3906\n",
            "Epoch: 3701, MSE: 0.5087\n",
            "Epoch: 3751, MSE: 0.5674\n",
            "Epoch: 3801, MSE: 0.5511\n",
            "Epoch: 3851, MSE: 0.4389\n",
            "Epoch: 3901, MSE: 0.2987\n",
            "Epoch: 3951, MSE: 0.2303\n"
          ]
        }
      ],
      "source": [
        "#Train:\n",
        "input_nf, output_nf, hidden_nf, coords = 5, 1, 24, 3\n",
        "optimizer_gcl = optim.Adam(gcl_layer.parameters(), lr=0.0001)\n",
        "loss_l1_gcl = nn.L1Loss()\n",
        "max_epoch = 4000\n",
        "batch_size = 32\n",
        "n_nodes = 6\n",
        "p = 0.5\n",
        "coord_dim = 3\n",
        "l = 2.5\n",
        "label = torch.full((batch_size * n_nodes, input_nf + coords), l)\n",
        "\n",
        "for i in range(max_epoch):\n",
        "  edges, edge_attr, tensor_edge_mask, adj_list = get_graph_batch(batch_size, n_nodes, p)\n",
        "  feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "  coord = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "  x = torch.cat([feat, coord], axis=1)\n",
        "  h_1, _ = gcl_layer(x = x, edge_index = edges, edge_mask = tensor_edge_mask)\n",
        "  loss = loss_l1_gcl(h_1, label)\n",
        "  loss.backward()\n",
        "  optimizer_gcl.step()\n",
        "  if i % 50 == 0:\n",
        "    print(\"Epoch: {}, MSE: {:.4f}\".format((i+1), loss))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zuxo6Sgf1N65"
      },
      "outputs": [],
      "source": [
        "edges, edge_attr, tensor_edge_mask, adj_list = get_graph_batch(batch_size, n_nodes, p)\n",
        "feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "coord = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "x = torch.cat([feat, coord], axis=1)\n",
        "h_1, _ = gcl_layer(x = x, edge_index = edges, edge_mask = tensor_edge_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj-IruTpFnYL",
        "outputId": "5e90de19-afc6-4d0f-e9e0-2aec2e7fa6a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0,   0,   0,   0,   0,   1,   1,   1,   1,   1,   2,   2,   2,   2,\n",
              "          2,   3,   3,   3,   3,   3,   4,   4,   4,   4,   4,   5,   5,   5,\n",
              "          5,   5,   6,   6,   6,   6,   6,   7,   7,   7,   7,   7,   8,   8,\n",
              "          8,   8,   8,   9,   9,   9,   9,   9,  10,  10,  10,  10,  10,  11,\n",
              "         11,  11,  11,  11,  12,  12,  12,  12,  12,  13,  13,  13,  13,  13,\n",
              "         14,  14,  14,  14,  14,  15,  15,  15,  15,  15,  16,  16,  16,  16,\n",
              "         16,  17,  17,  17,  17,  17,  18,  18,  18,  18,  18,  19,  19,  19,\n",
              "         19,  19,  20,  20,  20,  20,  20,  21,  21,  21,  21,  21,  22,  22,\n",
              "         22,  22,  22,  23,  23,  23,  23,  23,  24,  24,  24,  24,  24,  25,\n",
              "         25,  25,  25,  25,  26,  26,  26,  26,  26,  27,  27,  27,  27,  27,\n",
              "         28,  28,  28,  28,  28,  29,  29,  29,  29,  29,  30,  30,  30,  30,\n",
              "         30,  31,  31,  31,  31,  31,  32,  32,  32,  32,  32,  33,  33,  33,\n",
              "         33,  33,  34,  34,  34,  34,  34,  35,  35,  35,  35,  35,  36,  36,\n",
              "         36,  36,  36,  37,  37,  37,  37,  37,  38,  38,  38,  38,  38,  39,\n",
              "         39,  39,  39,  39,  40,  40,  40,  40,  40,  41,  41,  41,  41,  41,\n",
              "         42,  42,  42,  42,  42,  43,  43,  43,  43,  43,  44,  44,  44,  44,\n",
              "         44,  45,  45,  45,  45,  45,  46,  46,  46,  46,  46,  47,  47,  47,\n",
              "         47,  47,  48,  48,  48,  48,  48,  49,  49,  49,  49,  49,  50,  50,\n",
              "         50,  50,  50,  51,  51,  51,  51,  51,  52,  52,  52,  52,  52,  53,\n",
              "         53,  53,  53,  53,  54,  54,  54,  54,  54,  55,  55,  55,  55,  55,\n",
              "         56,  56,  56,  56,  56,  57,  57,  57,  57,  57,  58,  58,  58,  58,\n",
              "         58,  59,  59,  59,  59,  59,  60,  60,  60,  60,  60,  61,  61,  61,\n",
              "         61,  61,  62,  62,  62,  62,  62,  63,  63,  63,  63,  63,  64,  64,\n",
              "         64,  64,  64,  65,  65,  65,  65,  65,  66,  66,  66,  66,  66,  67,\n",
              "         67,  67,  67,  67,  68,  68,  68,  68,  68,  69,  69,  69,  69,  69,\n",
              "         70,  70,  70,  70,  70,  71,  71,  71,  71,  71,  72,  72,  72,  72,\n",
              "         72,  73,  73,  73,  73,  73,  74,  74,  74,  74,  74,  75,  75,  75,\n",
              "         75,  75,  76,  76,  76,  76,  76,  77,  77,  77,  77,  77,  78,  78,\n",
              "         78,  78,  78,  79,  79,  79,  79,  79,  80,  80,  80,  80,  80,  81,\n",
              "         81,  81,  81,  81,  82,  82,  82,  82,  82,  83,  83,  83,  83,  83,\n",
              "         84,  84,  84,  84,  84,  85,  85,  85,  85,  85,  86,  86,  86,  86,\n",
              "         86,  87,  87,  87,  87,  87,  88,  88,  88,  88,  88,  89,  89,  89,\n",
              "         89,  89,  90,  90,  90,  90,  90,  91,  91,  91,  91,  91,  92,  92,\n",
              "         92,  92,  92,  93,  93,  93,  93,  93,  94,  94,  94,  94,  94,  95,\n",
              "         95,  95,  95,  95,  96,  96,  96,  96,  96,  97,  97,  97,  97,  97,\n",
              "         98,  98,  98,  98,  98,  99,  99,  99,  99,  99, 100, 100, 100, 100,\n",
              "        100, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 103, 103, 103,\n",
              "        103, 103, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 106, 106,\n",
              "        106, 106, 106, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 109,\n",
              "        109, 109, 109, 109, 110, 110, 110, 110, 110, 111, 111, 111, 111, 111,\n",
              "        112, 112, 112, 112, 112, 113, 113, 113, 113, 113, 114, 114, 114, 114,\n",
              "        114, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 117, 117, 117,\n",
              "        117, 117, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119, 120, 120,\n",
              "        120, 120, 120, 121, 121, 121, 121, 121, 122, 122, 122, 122, 122, 123,\n",
              "        123, 123, 123, 123, 124, 124, 124, 124, 124, 125, 125, 125, 125, 125,\n",
              "        126, 126, 126, 126, 126, 127, 127, 127, 127, 127, 128, 128, 128, 128,\n",
              "        128, 129, 129, 129, 129, 129, 130, 130, 130, 130, 130, 131, 131, 131,\n",
              "        131, 131, 132, 132, 132, 132, 132, 133, 133, 133, 133, 133, 134, 134,\n",
              "        134, 134, 134, 135, 135, 135, 135, 135, 136, 136, 136, 136, 136, 137,\n",
              "        137, 137, 137, 137, 138, 138, 138, 138, 138, 139, 139, 139, 139, 139,\n",
              "        140, 140, 140, 140, 140, 141, 141, 141, 141, 141, 142, 142, 142, 142,\n",
              "        142, 143, 143, 143, 143, 143, 144, 144, 144, 144, 144, 145, 145, 145,\n",
              "        145, 145, 146, 146, 146, 146, 146, 147, 147, 147, 147, 147, 148, 148,\n",
              "        148, 148, 148, 149, 149, 149, 149, 149, 150, 150, 150, 150, 150, 151,\n",
              "        151, 151, 151, 151, 152, 152, 152, 152, 152, 153, 153, 153, 153, 153,\n",
              "        154, 154, 154, 154, 154, 155, 155, 155, 155, 155, 156, 156, 156, 156,\n",
              "        156, 157, 157, 157, 157, 157, 158, 158, 158, 158, 158, 159, 159, 159,\n",
              "        159, 159, 160, 160, 160, 160, 160, 161, 161, 161, 161, 161, 162, 162,\n",
              "        162, 162, 162, 163, 163, 163, 163, 163, 164, 164, 164, 164, 164, 165,\n",
              "        165, 165, 165, 165, 166, 166, 166, 166, 166, 167, 167, 167, 167, 167,\n",
              "        168, 168, 168, 168, 168, 169, 169, 169, 169, 169, 170, 170, 170, 170,\n",
              "        170, 171, 171, 171, 171, 171, 172, 172, 172, 172, 172, 173, 173, 173,\n",
              "        173, 173, 174, 174, 174, 174, 174, 175, 175, 175, 175, 175, 176, 176,\n",
              "        176, 176, 176, 177, 177, 177, 177, 177, 178, 178, 178, 178, 178, 179,\n",
              "        179, 179, 179, 179, 180, 180, 180, 180, 180, 181, 181, 181, 181, 181,\n",
              "        182, 182, 182, 182, 182, 183, 183, 183, 183, 183, 184, 184, 184, 184,\n",
              "        184, 185, 185, 185, 185, 185, 186, 186, 186, 186, 186, 187, 187, 187,\n",
              "        187, 187, 188, 188, 188, 188, 188, 189, 189, 189, 189, 189, 190, 190,\n",
              "        190, 190, 190, 191, 191, 191, 191, 191])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv_Hk4r_Fxkx",
        "outputId": "38025cad-3c3f-481c-ddce-c7613e9ad3b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([960, 1])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_attr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zUBZvvsmYCS"
      },
      "source": [
        "###MPNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZLskstIl-3a"
      },
      "outputs": [],
      "source": [
        "class MPNN(nn.Module):\n",
        "  def __init__(self, in_node_nf, coords, in_edge_nf, hidden_nf, device='cpu', act_fn=nn.SiLU(), n_layers=4, coords_weight=1.0, attention=False, node_attr=1):\n",
        "      super(MPNN, self).__init__()\n",
        "      self.hidden_nf = hidden_nf\n",
        "      self.device = device\n",
        "      self.n_layers = n_layers\n",
        "      ### Encoder\n",
        "      self.embedding = nn.Linear(in_node_nf + coords, hidden_nf)\n",
        "      self.node_attr = node_attr\n",
        "      if node_attr:\n",
        "          n_node_attr = in_node_nf + coords\n",
        "      else:\n",
        "          n_node_attr = 0\n",
        "      for i in range(0, n_layers):\n",
        "          self.add_module(\"gcl_%d\" % i, GCL(self.hidden_nf, self.hidden_nf, self.hidden_nf, nodes_att_dim=n_node_attr))\n",
        "\n",
        "      self.node_dec = nn.Sequential(nn.Linear(self.hidden_nf, self.hidden_nf),\n",
        "                                    act_fn,\n",
        "                                    nn.Linear(self.hidden_nf, 1 + coords))\n",
        "\n",
        "      self.to(self.device)\n",
        "\n",
        "  def forward(self, x, edges, edge_attr, edge_mask, n_nodes):\n",
        "    h = self.embedding(x)\n",
        "    for i in range(0, self.n_layers):\n",
        "        if self.node_attr:\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edges, edge_mask, edge_attr=None, node_attr = x)\n",
        "        else:\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](x, edge_index, edge_mask, edge_attr=None, node_attr=None)\n",
        "\n",
        "    pred = self.node_dec(h)\n",
        "    return pred.squeeze(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ybIi0eN1km_"
      },
      "outputs": [],
      "source": [
        "input_nf, output_nf, hidden_nf, coords = 5, 1, 24, 3\n",
        "mpnn = MPNN(in_node_nf=input_nf, coords=coords, in_edge_nf=1, hidden_nf=hidden_nf, n_layers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "rQMF3OCQ7dGx",
        "outputId": "a1f1023d-7d78-4575-fecc-6cec8851cb0b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-81b9ed274e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_edge_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_graph_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_nf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ],
      "source": [
        "batch_size = 5\n",
        "n_nodes = 6\n",
        "p = 0.5\n",
        "edges, edge_attr, tensor_edge_mask = get_graph_batch(batch_size, n_nodes, p)\n",
        "feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "coord = torch.rand(batch_size * n_nodes, coords)\n",
        "x = torch.cat([feat, coord], axis=1)\n",
        "h = mpnn(x, edges, edge_attr, tensor_edge_mask, n_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4U6SPHM7dNt"
      },
      "outputs": [],
      "source": [
        "input_nf, output_nf, hidden_nf, coords = 5, 1, 24, 3\n",
        "max_epoch = 4000\n",
        "batch_size = 32\n",
        "n_nodes = 6\n",
        "p = 0.5\n",
        "coord_dim = 3\n",
        "l = 2.5\n",
        "label = torch.full((batch_size * n_nodes, hidden_nf), l)\n",
        "mpnn = MPNN(in_node_nf=input_nf, coords=coords, in_edge_nf=1, hidden_nf=hidden_nf, n_layers=2)\n",
        "optimizer_mpnn = optim.Adam(mpnn.parameters(), lr=0.0001)\n",
        "loss_l1_mpnn = nn.L1Loss()\n",
        "\n",
        "\n",
        "for i in range(max_epoch):\n",
        "  edges, edge_attr, tensor_edge_mask = get_graph_batch(batch_size, n_nodes, p)\n",
        "  feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "  coord = torch.rand(batch_size * n_nodes, coords)\n",
        "  x = torch.cat([feat, coord], axis=1)\n",
        "  h_1 = mpnn(x, edges, edge_attr, tensor_edge_mask, n_nodes)\n",
        "  loss = loss_l1_mpnn(h_1, label)\n",
        "  loss.backward()\n",
        "  optimizer_mpnn.step()\n",
        "  if i % 50 == 0:\n",
        "    print(\"Epoch: {}, MSE: {:.4f}\".format((i+1), loss))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYTEnJr03tCk"
      },
      "outputs": [],
      "source": [
        "edges, edge_attr, tensor_edge_mask = get_graph_batch(batch_size, n_nodes, p)\n",
        "feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "coord = torch.rand(batch_size * n_nodes, coords)\n",
        "x = torch.cat([feat, coord], axis=1)\n",
        "h = mpnn(x, edges, edge_attr, tensor_edge_mask, n_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMPnMgfJlp3S"
      },
      "source": [
        "##Equivariant Graph Convolutional Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wdBZP5hJHg5"
      },
      "outputs": [],
      "source": [
        "#Layers :\n",
        "\n",
        "class E_GCL(nn.Module):\n",
        "    \"\"\"Graph Neural Net with global state and fixed number of nodes per graph.\n",
        "    Args:\n",
        "          hidden_dim: Number of hidden units.\n",
        "          num_nodes: Maximum number of nodes (for self-attentive pooling).\n",
        "          global_agg: Global aggregation function ('attn' or 'sum').\n",
        "          temp: Softmax temperature.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, edges_in_d=0, nodes_att_dim=0, act_fn=nn.ReLU(), recurrent=True, coords_weight=1.0, attention=False, clamp=False, norm_diff=False, tanh=False):\n",
        "        super(E_GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.coords_weight = coords_weight\n",
        "        self.recurrent = recurrent\n",
        "        self.attention = attention\n",
        "        self.norm_diff = norm_diff\n",
        "        self.tanh = tanh\n",
        "        edge_coords_nf = 1\n",
        "\n",
        "        #print(hidden_nf)\n",
        "        #print(input_nf)\n",
        "        #print(nodes_att_dim)\n",
        "\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edge_coords_nf + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        layer = nn.Linear(hidden_nf, 1, bias=False)\n",
        "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
        "\n",
        "        self.clamp = clamp\n",
        "        coord_mlp = []\n",
        "        coord_mlp.append(nn.Linear(hidden_nf, hidden_nf))\n",
        "        coord_mlp.append(act_fn)\n",
        "        coord_mlp.append(layer)\n",
        "        if self.tanh:\n",
        "            coord_mlp.append(nn.Tanh())\n",
        "            self.coords_range = nn.Parameter(torch.ones(1))*3\n",
        "        self.coord_mlp = nn.Sequential(*coord_mlp)\n",
        "\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "        #if recurrent:\n",
        "        #    self.gru = nn.GRUCell(hidden_nf, hidden_nf)\n",
        "\n",
        "\n",
        "    def edge_model(self, source, target, radial, edge_attr):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target, radial], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, radial, edge_attr], dim=1)\n",
        "        out = self.edge_mlp(out)\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(out)\n",
        "            out = out * att_val\n",
        "        return out\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0))\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        #print(type(node_attr))\n",
        "        #print(x.shape)\n",
        "        #print(agg.shape)\n",
        "        #print(node_attr.shape)\n",
        "        out = self.node_mlp(agg)\n",
        "        if self.recurrent:\n",
        "            out = x + out\n",
        "        return out, agg\n",
        "\n",
        "    def coord_model(self, coord, edge_index, coord_diff, edge_feat):\n",
        "        row, col = edge_index\n",
        "        trans = coord_diff * self.coord_mlp(edge_feat)\n",
        "        trans = torch.clamp(trans, min=-100, max=100) #This is never activated but just in case it case it explosed it may save the train\n",
        "        agg = unsorted_segment_mean(trans, row, num_segments=coord.size(0))\n",
        "        coord += agg*self.coords_weight\n",
        "        return coord\n",
        "\n",
        "\n",
        "    def coord2radial(self, edge_index, coord):\n",
        "        row, col = edge_index\n",
        "        coord_diff = coord[row] - coord[col]\n",
        "        #print(coord_diff)\n",
        "        radial = torch.sum((coord_diff)**2, 1).unsqueeze(1)\n",
        "        #print(radial)\n",
        "        if self.norm_diff:\n",
        "            norm = torch.sqrt(radial) + 1\n",
        "            coord_diff = coord_diff/(norm)\n",
        "\n",
        "        return radial, coord_diff\n",
        "\n",
        "    def forward(self, h, edge_index, coord, edge_attr=None, node_attr=None):\n",
        "        row, col = edge_index\n",
        "        radial, coord_diff = self.coord2radial(edge_index, coord)\n",
        "\n",
        "        edge_feat = self.edge_model(h[row], h[col], radial, edge_attr)\n",
        "        coord = self.coord_model(coord, edge_index, coord_diff, edge_feat)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        # coord = self.node_coord_model(h, coord)\n",
        "        # x = self.node_model(x, edge_index, x[col], u, batch)  # GCN\n",
        "        return h, coord, edge_attr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_1Db2haoDJg"
      },
      "outputs": [],
      "source": [
        "class E_GCL_mask(E_GCL):\n",
        "    \"\"\"Graph Neural Net with global state and fixed number of nodes per graph.\n",
        "    Args:\n",
        "          hidden_dim: Number of hidden units.\n",
        "          num_nodes: Maximum number of nodes (for self-attentive pooling).\n",
        "          global_agg: Global aggregation function ('attn' or 'sum').\n",
        "          temp: Softmax temperature.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, edges_in_d=0, nodes_attr_dim=0, act_fn=nn.ReLU(), recurrent=True, coords_weight=1.0, attention=False):\n",
        "        E_GCL.__init__(self, input_nf, output_nf, hidden_nf, edges_in_d=edges_in_d, nodes_att_dim=nodes_attr_dim, act_fn=act_fn, recurrent=recurrent, coords_weight=coords_weight, attention=attention)\n",
        "\n",
        "        del self.coord_mlp\n",
        "        self.act_fn = act_fn\n",
        "\n",
        "    def coord_model(self, coord, edge_index, coord_diff, edge_feat, edge_mask):\n",
        "        row, col = edge_index\n",
        "        trans = coord_diff * self.coord_mlp(edge_feat) * edge_mask\n",
        "        agg = unsorted_segment_sum(trans, row, num_segments=coord.size(0))\n",
        "        coord += agg*self.coords_weight\n",
        "        return coord\n",
        "\n",
        "    def forward(self, h, edge_index, coord, edge_mask, edge_attr=None, node_attr=None, n_nodes=None):\n",
        "        row, col = edge_index\n",
        "        radial, coord_diff = self.coord2radial(edge_index, coord)\n",
        "        edge_feat = self.edge_model(h[row], h[col], radial, edge_attr)\n",
        "\n",
        "        edge_feat = edge_feat * edge_mask\n",
        "\n",
        "        # TO DO: edge_feat = edge_feat * edge_mask\n",
        "\n",
        "        #coord = self.coord_model(coord, edge_index, coord_diff, edge_feat, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "\n",
        "        return h, coord, edge_attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-nCdiv-BnG2"
      },
      "outputs": [],
      "source": [
        "def visualize(h, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    if torch.is_tensor(h):\n",
        "        h = h.detach().cpu().numpy()\n",
        "        plt.scatter(h[:, 0], h[:, 1], s=140, cmap=\"Set2\")\n",
        "        if epoch is not None and loss is not None:\n",
        "            plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    else:\n",
        "        nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                          cmap=\"Set2\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj-P286iLmWc"
      },
      "outputs": [],
      "source": [
        "input_nf, output_nf, hidden_nf = 5, 1, 24\n",
        "\n",
        "e_gcl_layer = E_GCL_mask(input_nf, output_nf, hidden_nf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGoxhV8dVfpn"
      },
      "outputs": [],
      "source": [
        "batch_size = 1\n",
        "n_nodes = 4\n",
        "p = 1\n",
        "coord_dim = 3\n",
        "edges, edge_attr, tensor_edge_mask, adj_list = get_graph_batch(batch_size, n_nodes, p)\n",
        "feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "#x = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "x = torch.tensor([[0,0,0],[1,0,0],[0,1,0],[1,1,0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh63K3C0jUqT",
        "outputId": "aba10d95-3f60-4414-a185-dfd653e65bae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "execution_count": 36,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogg587BELehC"
      },
      "outputs": [],
      "source": [
        "h, x, edge_attr = e_gcl_layer(feat, edges, x, tensor_edge_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVsIIaEua8XG"
      },
      "outputs": [],
      "source": [
        "h.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJHfbRE369U7"
      },
      "source": [
        "###Overfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViaWM6uceQhh",
        "outputId": "d86fc2ac-d615-4dd7-ee9f-7b5e81785001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, MSE: 1.6456\n",
            "Epoch: 51, MSE: 1.5301\n",
            "Epoch: 101, MSE: 1.3233\n",
            "Epoch: 151, MSE: 1.0562\n",
            "Epoch: 201, MSE: 0.6513\n",
            "Epoch: 251, MSE: 0.4786\n",
            "Epoch: 301, MSE: 0.6678\n",
            "Epoch: 351, MSE: 0.7434\n",
            "Epoch: 401, MSE: 0.4029\n",
            "Epoch: 451, MSE: 0.3686\n",
            "Epoch: 501, MSE: 0.4575\n",
            "Epoch: 551, MSE: 0.4764\n",
            "Epoch: 601, MSE: 0.3027\n",
            "Epoch: 651, MSE: 0.1754\n",
            "Epoch: 701, MSE: 0.3022\n",
            "Epoch: 751, MSE: 0.3572\n",
            "Epoch: 801, MSE: 0.3375\n",
            "Epoch: 851, MSE: 0.2134\n",
            "Epoch: 901, MSE: 0.1066\n",
            "Epoch: 951, MSE: 0.0991\n",
            "Epoch: 1001, MSE: 0.1458\n",
            "Epoch: 1051, MSE: 0.1267\n",
            "Epoch: 1101, MSE: 0.0558\n",
            "Epoch: 1151, MSE: 0.0577\n",
            "Epoch: 1201, MSE: 0.1428\n",
            "Epoch: 1251, MSE: 0.1824\n",
            "Epoch: 1301, MSE: 0.1699\n",
            "Epoch: 1351, MSE: 0.1099\n",
            "Epoch: 1401, MSE: 0.0079\n",
            "Epoch: 1451, MSE: 0.0995\n",
            "Epoch: 1501, MSE: 0.1623\n",
            "Epoch: 1551, MSE: 0.1869\n",
            "Epoch: 1601, MSE: 0.1657\n",
            "Epoch: 1651, MSE: 0.0932\n",
            "Epoch: 1701, MSE: 0.0270\n",
            "Epoch: 1751, MSE: 0.1410\n",
            "Epoch: 1801, MSE: 0.1918\n",
            "Epoch: 1851, MSE: 0.1881\n",
            "Epoch: 1901, MSE: 0.1315\n",
            "Epoch: 1951, MSE: 0.0262\n",
            "Epoch: 2001, MSE: 0.0988\n",
            "Epoch: 2051, MSE: 0.1754\n",
            "Epoch: 2101, MSE: 0.2052\n",
            "Epoch: 2151, MSE: 0.1885\n",
            "Epoch: 2201, MSE: 0.0630\n",
            "Epoch: 2251, MSE: 0.1350\n",
            "Epoch: 2301, MSE: 0.1123\n",
            "Epoch: 2351, MSE: 0.0458\n",
            "Epoch: 2401, MSE: 0.0327\n",
            "Epoch: 2451, MSE: 0.0748\n",
            "Epoch: 2501, MSE: 0.0498\n",
            "Epoch: 2551, MSE: 0.0406\n",
            "Epoch: 2601, MSE: 0.1012\n",
            "Epoch: 2651, MSE: 0.0873\n",
            "Epoch: 2701, MSE: 0.0041\n",
            "Epoch: 2751, MSE: 0.1084\n",
            "Epoch: 2801, MSE: 0.1415\n",
            "Epoch: 2851, MSE: 0.0921\n",
            "Epoch: 2901, MSE: 0.0369\n",
            "Epoch: 2951, MSE: 0.1552\n",
            "Epoch: 3001, MSE: 0.1887\n",
            "Epoch: 3051, MSE: 0.1332\n",
            "Epoch: 3101, MSE: 0.0094\n",
            "Epoch: 3151, MSE: 0.1612\n",
            "Epoch: 3201, MSE: 0.2318\n",
            "Epoch: 3251, MSE: 0.2166\n",
            "Epoch: 3301, MSE: 0.1129\n",
            "Epoch: 3351, MSE: 0.0700\n",
            "Epoch: 3401, MSE: 0.2214\n",
            "Epoch: 3451, MSE: 0.2863\n",
            "Epoch: 3501, MSE: 0.2608\n",
            "Epoch: 3551, MSE: 0.1440\n",
            "Epoch: 3601, MSE: 0.0506\n",
            "Epoch: 3651, MSE: 0.2240\n",
            "Epoch: 3701, MSE: 0.3158\n",
            "Epoch: 3751, MSE: 0.3270\n",
            "Epoch: 3801, MSE: 0.2551\n",
            "Epoch: 3851, MSE: 0.1009\n",
            "Epoch: 3901, MSE: 0.1137\n",
            "Epoch: 3951, MSE: 0.2785\n"
          ]
        }
      ],
      "source": [
        "#Train:\n",
        "from torch import nn, optim\n",
        "optimizer = optim.Adam(e_gcl_layer.parameters(), lr=0.0001)\n",
        "loss_l1 = nn.L1Loss()\n",
        "max_epoch = 4000\n",
        "batch_size = 32\n",
        "n_nodes = 6\n",
        "p = 0.5\n",
        "coord_dim = 3\n",
        "l = 2.5\n",
        "label = torch.full((batch_size * n_nodes, input_nf), l)\n",
        "\n",
        "for i in range(max_epoch):\n",
        "  edges, edge_attr, tensor_edge_mask, adj_list = get_graph_batch(batch_size, n_nodes, p)\n",
        "  feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "  x = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "  h_1, _, _ = e_gcl_layer(feat, edges, x, tensor_edge_mask)\n",
        "  loss = loss_l1(h_1, label)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % 50 == 0:\n",
        "    print(\"Epoch: {}, MSE: {:.4f}\".format((i+1), loss))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_deq4OBfJaJ"
      },
      "outputs": [],
      "source": [
        "edges, edge_attr, tensor_edge_mask = get_graph_batch(batch_size, n_nodes, p)\n",
        "feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "x = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "h_1, _, _ = e_gcl_layer(feat, edges, x, tensor_edge_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOpxPTJ9fPST"
      },
      "outputs": [],
      "source": [
        "h_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz9gtZ1pYhRj"
      },
      "source": [
        "###EGNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx0k7_-yZDAG"
      },
      "outputs": [],
      "source": [
        "class EGNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, device='cpu', act_fn=nn.SiLU(), n_layers=4, coords_weight=1.0, attention=False, node_attr=1):\n",
        "        super(EGNN, self).__init__()\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        ### Encoder\n",
        "        self.embedding = nn.Linear(in_node_nf, hidden_nf)\n",
        "        self.node_attr = node_attr\n",
        "        if node_attr:\n",
        "            n_node_attr = in_node_nf\n",
        "        else:\n",
        "            n_node_attr = 0\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, E_GCL_mask(self.hidden_nf, self.hidden_nf, self.hidden_nf, edges_in_d=in_edge_nf, nodes_attr_dim=n_node_attr, act_fn=act_fn, recurrent=True, coords_weight=coords_weight, attention=attention))\n",
        "\n",
        "        self.node_dec = nn.Sequential(nn.Linear(self.hidden_nf, self.hidden_nf),\n",
        "                                      act_fn,\n",
        "                                      nn.Linear(self.hidden_nf, 1))\n",
        "\n",
        "        self.graph_dec = nn.Sequential(nn.Linear(self.hidden_nf, self.hidden_nf),\n",
        "                                       act_fn,\n",
        "                                       nn.Linear(self.hidden_nf, 1))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h0, x, edges, edge_attr, edge_mask, n_nodes):\n",
        "        h = self.embedding(h0)\n",
        "        for i in range(0, self.n_layers):\n",
        "            if self.node_attr:\n",
        "                h, x, _ = self._modules[\"gcl_%d\" % i](h, edges, x, edge_mask, edge_attr=edge_attr, node_attr=h0, n_nodes=n_nodes)\n",
        "            else:\n",
        "                h, x, _ = self._modules[\"gcl_%d\" % i](h, edges, x, edge_mask, edge_attr=edge_attr,\n",
        "                                                      node_attr=None, n_nodes=n_nodes)\n",
        "\n",
        "        pred = self.node_dec(h)\n",
        "        return pred.squeeze(1).reshape(-1,1), x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LRD-QP9h9mQ"
      },
      "outputs": [],
      "source": [
        "input_nf, output_nf, hidden_nf = 5, 1, 24\n",
        "\n",
        "egnn = EGNN(in_node_nf=input_nf, in_edge_nf=1, hidden_nf=hidden_nf, n_layers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kteCNCJ2ilN_"
      },
      "outputs": [],
      "source": [
        "n_nodes = 6\n",
        "p = 0.5\n",
        "coord_dim = 3\n",
        "batch_size = 32\n",
        "l = 2.5\n",
        "edges, edge_attr, tensor_edge_mask, adj_list = get_graph_batch(batch_size, n_nodes, p)\n",
        "feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "x = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "h = egnn(feat, x, edges, edge_attr, tensor_edge_mask, n_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLp7BcyzhaW6"
      },
      "outputs": [],
      "source": [
        "h[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "NiOZep0_jN-2",
        "outputId": "c51a8aec-8631-498e-811d-c7e794243fa1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a0629570bc61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_nf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0megnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_node_nf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_nf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_edge_nf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_nf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_nf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moptimizer_egnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0megnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mloss_l1_egnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
          ]
        }
      ],
      "source": [
        "input_nf, output_nf, hidden_nf = 5, 1, 24\n",
        "max_epoch = 4000\n",
        "batch_size = 32\n",
        "n_nodes = 6\n",
        "p = 0.5\n",
        "coord_dim = 3\n",
        "l = 2.5\n",
        "label = torch.full((batch_size * n_nodes, hidden_nf), l)\n",
        "egnn = EGNN(in_node_nf=input_nf, in_edge_nf=1, hidden_nf=hidden_nf, n_layers=2)\n",
        "optimizer_egnn = optim.Adam(egnn.parameters(), lr=0.0001)\n",
        "loss_l1_egnn = nn.L1Loss()\n",
        "\n",
        "\n",
        "for i in range(max_epoch):\n",
        "  edges, edge_attr, tensor_edge_mask = get_graph_batch(batch_size, n_nodes, p)\n",
        "  feat = torch.ones(batch_size * n_nodes, input_nf)\n",
        "  x = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "  h_1 = egnn(feat, x, edges, edge_attr, tensor_edge_mask, n_nodes)\n",
        "  loss = loss_l1_egnn(h_1, label)\n",
        "  loss.backward()\n",
        "  optimizer_egnn.step()\n",
        "  if i % 50 == 0:\n",
        "    print(\"Epoch: {}, MSE: {:.4f}\".format((i+1), loss))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tH_PkshPlfJ1"
      },
      "outputs": [],
      "source": [
        "edges, edge_attr, tensor_edge_mask = get_graph_batch(batch_size, n_nodes, p)\n",
        "feat = torch.rand(batch_size * n_nodes, input_nf)\n",
        "x = torch.rand(batch_size * n_nodes, coord_dim)\n",
        "h_1 = egnn(feat, x, edges, edge_attr, tensor_edge_mask, n_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl3-QduHlZLC"
      },
      "outputs": [],
      "source": [
        "h_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQIrtWmd1IQO"
      },
      "source": [
        "## Generate Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aRdkYFb1R1w"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.spatial import ConvexHull\n",
        "class LabelGenerate():\n",
        "  def __init__(self, x, h, edges, edge_attr, batch_size, n_nodes, graphs):\n",
        "    # Returns (x', h'), where x' is invariant to E(n), and h' is equivariant to E(n)\n",
        "    #x' = x + g(x,h,G) = x + p(h)* A * phi(x) * f_1(x)\n",
        "    #h = p(h) * A * f_2(x)\n",
        "\n",
        "\n",
        "    self.x = x\n",
        "    self.h = h\n",
        "    self.edges = edges\n",
        "    self.edge_attr = edge_attr\n",
        "    self.batch_size = batch_size\n",
        "    self.n = n_nodes\n",
        "    self.graphs = graphs\n",
        "    #self.W = \n",
        "\n",
        "  def x_1(self, feat):\n",
        "    dmatrix = np.empty(shape=(self.batch_size , self.n, self.x.shape[1]))\n",
        "    c=0\n",
        "    for i in range(0, self.x.shape[0], self.n):\n",
        "\n",
        "      g = self.graphs[c]\n",
        "      graph = self.x[i:i+self.n]\n",
        "      s = graph[:, :, None] - graph[:, :, None].T\n",
        "      s_swap = np.array(np.swapaxes(s, 1, 2))\n",
        "      #f_x = (np.array(feat[i:i+self.n].sum(1)).reshape((self.n, 1, 1)) * s_swap * g.reshape((self.n,self.n,1))).sum(1)\n",
        "      f_x = (np.array(feat[i:i+self.n].sum(1)).reshape((self.n, 1, 1)) * s_swap ).sum(1)\n",
        "      dmatrix[c] = f_x\n",
        "      c+=1\n",
        "\n",
        "    return self.x + dmatrix.reshape(-1, dmatrix.shape[2])\n",
        "\n",
        "    \n",
        "\n",
        "  def h_1(self, feat, type_f2 = 'distance'):\n",
        "\n",
        "    if type_f2 == 'volume':\n",
        "    \n",
        "      volume = np.empty(shape = (self.batch_size, self.n, 1))\n",
        "      ones = np.ones(shape = (self.n, 1))\n",
        "      c = 0\n",
        "      for i in range(0, self.x.shape[0], self.n):\n",
        "        g = self.graphs[c]\n",
        "        coords = self.x[i:i+self.n]\n",
        "        #print(coords)\n",
        "        vol = ConvexHull(coords).volume\n",
        "        vol_array = ones * np.array(vol)\n",
        "        f_2x = np.array((feat[i:i+self.n].sum(1) * g @ vol_array))\n",
        "        volume[c] = f_2x\n",
        "        c+=1\n",
        "      h_1 = volume\n",
        "\n",
        "    elif type_f2 == 'area':\n",
        "\n",
        "      area = np.empty(shape = (self.batch_size, self.n, 1))\n",
        "      ones = np.ones(shape = (self.n, 1))\n",
        "      c = 0\n",
        "      for i in range(0, self.x.shape[0], self.n):\n",
        "        g = self.graphs[c]\n",
        "        coords = self.x[i:i+self.n]\n",
        "        #print(coords)\n",
        "        area_coord = ConvexHull(coords).area\n",
        "        area_array = ones * np.array(area_coord)\n",
        "        f_2x = np.array((feat[i:i+self.n].sum(1) * g @ area_array))\n",
        "        area[c] = f_2x\n",
        "        c+=1\n",
        "      h_1 = area\n",
        "\n",
        "    elif type_f2 == 'distance':\n",
        "      \n",
        "      dist = np.empty(shape = (self.batch_size, self.n, 1))\n",
        "      c = 0\n",
        "      \n",
        "      for i in range(0, self.x.shape[0], self.n):\n",
        "        g = self.graphs[c]\n",
        "        coords = self.x[i:i+self.n]\n",
        "        d = squareform(pdist(coords))\n",
        "        f_2x = (g * d * np.array(feat[i:i+self.n].sum(1))).sum(1)\n",
        "        dist[c] = f_2x.reshape(-1, 1)\n",
        "        c+=1\n",
        "        \n",
        "      h_1 = dist\n",
        "\n",
        "    elif type_f2 == 'angles':\n",
        "      angles = np.empty(shape = (self.batch_size, self.n, 1))\n",
        "      c = 0\n",
        "      for i in range(0, self.x.shape[0], self.n):\n",
        "        g = self.graphs[c]\n",
        "        coords = self.x[i:i+self.n]\n",
        "        d = np.zeros((self.n, self.n))\n",
        "        for i in range(self.n):\n",
        "          for j in range(self.n):\n",
        "            v = coords[i,:]\n",
        "            w = coords[j,:]\n",
        "            angle_ij = np.arccos(v.dot(w)/(np.linalg.norm(v)*np.linalg.norm(w)))\n",
        "            d[i,j] = angle_ij\n",
        "        d = squareform(pdist(coords))\n",
        "        f_2x = (g * d * np.array(feat[i:i+self.n].sum(1))).sum(1)\n",
        "        angles[c] = f_2x.reshape(-1, 1)\n",
        "        c+=1\n",
        "      h_1 = angles\n",
        "\n",
        "    return h_1.reshape(-1, h_1.shape[2])\n",
        "\n",
        "\n",
        "\n",
        "  def p(self):\n",
        "    #simply exponential\n",
        "    #return np.exp(self.h)\n",
        "    return self.h\n",
        "    #return np.ones(shape=self.h.shape)\n",
        "\n",
        "  def get_labels(self, type_f2 = 'distance'):\n",
        "\n",
        "    p = self.p()\n",
        "    x_1 = self.x_1(p)\n",
        "    h_1 = self.h_1(p, type_f2)\n",
        "    #Standard Normalization\n",
        "    #print(type(x_1))\n",
        "    #x_1 = (x_1 - torch.mean(x_1))/torch.std(x_1)\n",
        "    #h_1 = (h_1 - np.mean(h_1))/np.std(h_1)\n",
        "    #Frobenius Normalization\n",
        "    return x_1, h_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHiBHy4E6PGz"
      },
      "outputs": [],
      "source": [
        "p=0.5\n",
        "graphs = []\n",
        "for i in range(batch_size):\n",
        "  G = nx.erdos_renyi_graph(n_nodes, p)\n",
        "  adj = np.array(nx.linalg.graphmatrix.adjacency_matrix(G).todense())\n",
        "  graphs.append(adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsU1fE4o6h9h"
      },
      "outputs": [],
      "source": [
        "l_gen = LabelGenerate(x, h, edges, edge_attr, batch_size, n_nodes, graphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj1z4RLu8evW"
      },
      "outputs": [],
      "source": [
        "l_gen_2 = LabelGenerate(x + np.array([1,1,1]), h, edges, edge_attr, batch_size, n_nodes, graphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "kxxg-akG6mQH",
        "outputId": "db717bd7-08e6-487d-a06e-a0946aff2b0a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-cd86d02d2d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_2\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0ml_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_f2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'distance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-89-1f7d8c2de7ab>\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(self, type_f2)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mh_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_f2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m#Standard Normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-1f7d8c2de7ab>\u001b[0m in \u001b[0;36mx_1\u001b[0;34m(self, feat)\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0ms_swap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m#f_x = (np.array(feat[i:i+self.n].sum(1)).reshape((self.n, 1, 1)) * s_swap * g.reshape((self.n,self.n,1))).sum(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mf_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms_swap\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mdmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mc\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4 into shape (6,1,1)"
          ]
        }
      ],
      "source": [
        "x_2, h_2 =  l_gen.get_labels(type_f2 = 'distance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZZX1b088X03"
      },
      "outputs": [],
      "source": [
        "x_3, h_3 =  l_gen_2.get_labels(type_f2 = 'distance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vujroj48ZgV",
        "outputId": "18a36942-38b8-4586-a4a0-93659ac6d99a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.linalg.norm(h_3 - h_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI2L7F36_mqu",
        "outputId": "b6092c66-a1f9-490e-b3cc-8d67a86ed44f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000],\n",
              "        [1.0000, 1.0000, 1.0000]], dtype=torch.float64)"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_3 - x_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXfeK4S380n1",
        "outputId": "51bd7c07-98a3-4abe-c79c-61770a294c54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.07743948],\n",
              "       [0.02725298],\n",
              "       [0.10319543],\n",
              "       [0.07248706],\n",
              "       [0.13208133],\n",
              "       [0.05677085],\n",
              "       [0.08703128],\n",
              "       [0.08808563],\n",
              "       [0.06125402],\n",
              "       [0.09030158],\n",
              "       [0.07095722],\n",
              "       [0.15491455],\n",
              "       [0.09135788],\n",
              "       [0.10850103],\n",
              "       [0.        ],\n",
              "       [0.103842  ],\n",
              "       [0.10191548],\n",
              "       [0.06669638],\n",
              "       [0.09313365],\n",
              "       [0.10901485],\n",
              "       [0.06001022],\n",
              "       [0.11550358],\n",
              "       [0.08351206],\n",
              "       [0.0555909 ],\n",
              "       [0.11122989],\n",
              "       [0.10611257],\n",
              "       [0.08184737],\n",
              "       [0.03302928],\n",
              "       [0.02202014],\n",
              "       [0.02761344],\n",
              "       [0.0953065 ],\n",
              "       [0.07613777],\n",
              "       [0.07389257],\n",
              "       [0.10747883],\n",
              "       [0.0649263 ],\n",
              "       [0.03969524]])"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY_Dw6Aa6TKv"
      },
      "source": [
        "##Experiment 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvd9FiZ17HWW"
      },
      "outputs": [],
      "source": [
        "#Fixed Graph and Node Features: \n",
        "#Vary Label Functions. Try to find Equivariant Labels that EGNN can't learn by MPNN does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijwpxyziSvO4",
        "outputId": "8f47d876-cc07-4c19-c33f-43df490c2528"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5105],\n",
              "        [0.3904],\n",
              "        [0.5372]])"
            ]
          },
          "execution_count": 113,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.normal(mean= 0.5, std=0.1, size=(3,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyNMFKOAbTNx"
      },
      "outputs": [],
      "source": [
        "#GENERATE DATASET:\n",
        "\n",
        "#Generate a graph:\n",
        "n_nodes = 6\n",
        "p = 0.5\n",
        "edges, edge_attr, tensor_edge_mask, adj_list = get_graph_batch(1, n_nodes, p)\n",
        "input_nf, output_nf, hidden_nf, coords = 5, 1, 24, 3\n",
        "mu, sigma = 0,1\n",
        "\n",
        "#Dataset(Train-Val-Test)\n",
        "\n",
        "#Train:\n",
        "\n",
        "training_set_size = 10000\n",
        "adj_list_tr = adj_list * training_set_size\n",
        "edges_0_tr = torch.cat([edges[0]] * training_set_size)\n",
        "edges_1_tr = torch.cat([edges[1]] * training_set_size)\n",
        "edges_tr = [edges_0_tr, edges_1_tr]\n",
        "edge_attr_tr = torch.cat([edge_attr] * training_set_size)\n",
        "tensor_edge_mask_tr = torch.cat([tensor_edge_mask] * training_set_size)\n",
        "\n",
        "#Generare Node Features and Coordinates\n",
        "feat_tr = torch.ones(training_set_size * n_nodes, input_nf)\n",
        "coord_tr = torch.normal(mean=mu,std=sigma,size=(training_set_size * n_nodes, coords))\n",
        "\n",
        "#Val:\n",
        "validation_set_size = 500\n",
        "adj_list_val = adj_list * validation_set_size\n",
        "edges_0_val = torch.cat([edges[0]] * validation_set_size)\n",
        "edges_1_val = torch.cat([edges[1]] * validation_set_size)\n",
        "edges_val = [edges_0_val, edges_1_val]\n",
        "edge_attr_val = torch.cat([edge_attr] * validation_set_size)\n",
        "tensor_edge_mask_val = torch.cat([tensor_edge_mask] * validation_set_size)\n",
        "\n",
        "#Generare Node Features and Coordinates\n",
        "feat_val = torch.ones(validation_set_size * n_nodes, input_nf)\n",
        "coord_val = torch.normal(mean=mu,std=sigma,size=(validation_set_size * n_nodes, coords))\n",
        "\n",
        "#Test:\n",
        "test_set_size = 500\n",
        "adj_list_test = adj_list * test_set_size\n",
        "edges_0_test = torch.cat([edges[0]] * test_set_size)\n",
        "edges_1_test = torch.cat([edges[1]] * test_set_size)\n",
        "edges_test = [edges_0_test, edges_1_test]\n",
        "edge_attr_test = torch.cat([edge_attr] * test_set_size)\n",
        "tensor_edge_mask_test = torch.cat([tensor_edge_mask] * test_set_size)\n",
        "\n",
        "#Generare Node Features and Coordinates\n",
        "feat_test = torch.ones(test_set_size * n_nodes, input_nf)\n",
        "coord_test = torch.normal(mean=mu,std=sigma,size=(test_set_size * n_nodes, coords))\n",
        "\n",
        "#Generate Labels: Training Set\n",
        "l_gen_tr = LabelGenerate(coord_tr, feat_tr, edges_tr, edge_attr_tr, training_set_size, n_nodes, adj_list_tr)\n",
        "x_tr, h_tr =  l_gen_tr.get_labels(type_f2 = 'distance')\n",
        "#Generate Labels: Validation Set\n",
        "l_gen_val = LabelGenerate(coord_val, feat_val, edges_val, edge_attr_val, validation_set_size, n_nodes, adj_list_val)\n",
        "x_val, h_val =  l_gen_val.get_labels(type_f2 = 'distance')\n",
        "#Generate Labels: Test Set\n",
        "l_gen_test = LabelGenerate(coord_test, feat_test, edges_test, edge_attr_test, test_set_size, n_nodes, adj_list_test)\n",
        "x_test, h_test =  l_gen_test.get_labels(type_f2 = 'distance')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDBvZrLA0Mio"
      },
      "outputs": [],
      "source": [
        "#Shuffle Training Set\n",
        "def shuffle(adj_list, edges_0, edges_1, edge_attr, tensor_edge_mask, feat, coord, x_label, h_label, training_set_size, n_nodes):\n",
        "  perm = np.random.permutation(training_set_size)\n",
        "  adj_list = [adj_list[i] for i in perm]\n",
        "  feat = torch.cat([feat[n_nodes*i:n_nodes*i + n_nodes, :] for i in perm])\n",
        "  coord = torch.cat([coord[n_nodes*i:n_nodes*i + n_nodes, :] for i in perm])\n",
        "  tensor_edge_mask = torch.cat([tensor_edge_mask[n_nodes*(n_nodes-1)*i:n_nodes*(n_nodes-1)*i + n_nodes*(n_nodes-1), :] for i in perm])\n",
        "  edge_attr = torch.cat([edge_attr[n_nodes*(n_nodes-1)*i:n_nodes*(n_nodes-1)*i + n_nodes*(n_nodes-1), :] for i in perm])\n",
        "  edges_0 = torch.cat([edges_0[n_nodes*(n_nodes-1)*i:n_nodes*(n_nodes-1)*i + n_nodes*(n_nodes-1)] for i in perm])\n",
        "  edges_1 = torch.cat([edges_1[n_nodes*(n_nodes-1)*i:n_nodes*(n_nodes-1)*i + n_nodes*(n_nodes-1)] for i in perm])\n",
        "  edges = [edges_0, edges_1]\n",
        "  x_label = torch.cat([x_label[n_nodes*i:n_nodes*i + n_nodes, :] for i in perm])\n",
        "  h_label = np.concatenate([h_label[n_nodes*i:n_nodes*i + n_nodes, :] for i in perm])\n",
        "  return adj_list, feat, coord, tensor_edge_mask, edge_attr, edges, x_label, h_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoDoh2K5Bgry"
      },
      "outputs": [],
      "source": [
        "adj_list_tr, feat_tr, coord_tr, tensor_edge_mask_tr, edge_attr_tr, edges_tr, x_tr, h_tr = shuffle(adj_list_tr, \n",
        "                                                                                                  edges_0_tr, \n",
        "                                                                                                  edges_1_tr, \n",
        "                                                                                                  edge_attr_tr, \n",
        "                                                                                                  tensor_edge_mask_tr, \n",
        "                                                                                                  feat_tr, coord_tr, x_tr, h_tr,\n",
        "                                                                                                  training_set_size, n_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-pV8bRcEmiy"
      },
      "outputs": [],
      "source": [
        "mpnn = MPNN(in_node_nf=input_nf, coords=coords, in_edge_nf=1, hidden_nf=hidden_nf, n_layers=2)\n",
        "egnn = EGNN(in_node_nf=input_nf, in_edge_nf=1, hidden_nf=hidden_nf, n_layers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "hLHjCMl8Yfjk",
        "outputId": "79f32aa9-0df1-4b2d-8bd9-0ab0362b0632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Iteration: 0, MPNN MSE: 24.3746, EGNN MSE: 23.7716\n",
            "Epoch: 1, Iteration: 50, MPNN MSE: 24.9609, EGNN MSE: 24.4464\n",
            "Epoch: 2, Iteration: 0, MPNN MSE: 24.0601, EGNN MSE: 23.5729\n",
            "Epoch: 2, Iteration: 50, MPNN MSE: 24.7330, EGNN MSE: 24.2888\n",
            "Epoch: 3, Iteration: 0, MPNN MSE: 23.7164, EGNN MSE: 23.3453\n",
            "Epoch: 3, Iteration: 50, MPNN MSE: 24.1838, EGNN MSE: 23.8147\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-bf4f6a0bc45f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss_egnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_l1_egnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_egnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mloss_mpnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss_egnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0moptimizer_mpnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0moptimizer_egnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Train\n",
        "from torch import nn, optim\n",
        "\n",
        "max_epoch = 1000\n",
        "optimizer_mpnn = optim.Adam(mpnn.parameters(), lr=0.0001)\n",
        "loss_l1_mpnn = nn.L1Loss()\n",
        "optimizer_egnn = optim.Adam(egnn.parameters(), lr=0.0001)\n",
        "loss_l1_egnn = nn.L1Loss()\n",
        "batch_size = 100\n",
        "iteration = training_set_size // batch_size\n",
        "\n",
        "for i in range(max_epoch):\n",
        "  \"\"\"adj_list_tr, feat_tr, coord_tr, tensor_edge_mask_tr, edge_attr_tr, edges_tr, x_tr, h_tr = shuffle(adj_list_tr, \n",
        "                                                                                                    edges_0_tr, \n",
        "                                                                                                    edges_1_tr, \n",
        "                                                                                                    edge_attr_tr, \n",
        "                                                                                                    tensor_edge_mask_tr, \n",
        "                                                                                                    feat_tr, coord_tr, x_tr, h_tr,\n",
        "                                                                                                    training_set_size, n_nodes)\n",
        "  \"\"\"\n",
        "  for iters in range(iteration):\n",
        "    #Each iteration is process #batch_size number of graphs\n",
        "\n",
        "    coord = coord_tr[iters*batch_size*n_nodes:(iters+1)*batch_size*n_nodes,:]\n",
        "    feat = feat_tr[iters*batch_size*n_nodes:(iters+1)*batch_size*n_nodes,:]\n",
        "    x_1 = x_tr[iters*batch_size*n_nodes:(iters+1)*batch_size*n_nodes,:]\n",
        "    h_1 = h_tr[iters*batch_size*n_nodes:(iters+1)*batch_size*n_nodes,:]\n",
        "    h_1 = torch.tensor(h_1)\n",
        "    edges_0 = edges_tr[0][iters*batch_size*n_nodes*(n_nodes-1):(iters+1)*batch_size*n_nodes*(n_nodes-1)]\n",
        "    edges_1 = edges_tr[1][iters*batch_size*n_nodes*(n_nodes-1):(iters+1)*batch_size*n_nodes*(n_nodes-1)]\n",
        "    edges = [edges_0, edges_1]\n",
        "    \n",
        "    edge_attr = edge_attr_tr[iters*batch_size*n_nodes*(n_nodes-1):(iters+1)*batch_size*n_nodes*(n_nodes-1),:]\n",
        "    tensor_edge_mask = tensor_edge_mask_tr[iters*batch_size*n_nodes*(n_nodes-1):(iters+1)*batch_size*n_nodes*(n_nodes-1),:]\n",
        "    x = torch.cat([feat, coord], axis=1)\n",
        "    out_mpnn = mpnn(x, edges, edge_attr, tensor_edge_mask, n_nodes)\n",
        "    #h_mpnn, x_mpnn = out_mpnn[:,0], out_mpnn[:,1:]\n",
        "    h_egnn, x_egnn = egnn(feat, coord, edges, edge_attr, tensor_edge_mask, n_nodes)\n",
        "    out_egnn = torch.cat([x_egnn, h_egnn],axis=1)\n",
        "    label = torch.cat([x_1, h_1], axis=1)\n",
        "    loss_mpnn = loss_l1_mpnn(out_mpnn, label)\n",
        "    loss_egnn = loss_l1_egnn(out_egnn, label)\n",
        "    loss_mpnn.backward()\n",
        "    loss_egnn.backward()\n",
        "    optimizer_mpnn.step()\n",
        "    optimizer_egnn.step()\n",
        "    if iters % 50 == 0:\n",
        "      print(\"Epoch: {}, Iteration: {}, MPNN MSE: {:.4f}, EGNN MSE: {:.4f}\".format((i+1), iters, loss_mpnn, loss_egnn))\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW57sIRmwM9k",
        "outputId": "7ce3d743-c8fb-477c-ab74-e06199ecb7c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3000])\n"
          ]
        }
      ],
      "source": [
        "print(edges_0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoqmowsiwXdW",
        "outputId": "de3b3633-cbef-4c35-c92b-0142711452b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
              "        4, 5, 5, 5, 5, 5])"
            ]
          },
          "execution_count": 36,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges_0[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tiBnpdMw6TJ",
        "outputId": "3bc88725-af85-4097-924c-1621e9e050fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 0, 2, 3, 4, 5, 0, 1, 3, 4, 5, 0, 1, 2, 4, 5, 0, 1, 2, 3,\n",
              "        5, 0, 1, 2, 3, 4])"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges_1[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB36Fm8hw8sQ",
        "outputId": "51c1a8b5-a905-4ea2-8534-cde317da0960"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 1],\n",
              "       [0, 1, 0, 1, 0, 0],\n",
              "       [1, 1, 1, 0, 0, 1],\n",
              "       [1, 0, 0, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 0]], dtype=int64)"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adj_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92wmrbgUwqAt",
        "outputId": "2664d4e1-5be6-420b-f0a8-2b64fb40c74b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([300000])"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges_tr[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvt1DU7nwU6B",
        "outputId": "2f216a62-9626-4797-97d5-71572a5dea75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([600, 8])\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRDNWx6G6XCQ"
      },
      "source": [
        "##Experiment 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUy_45IF7H7O"
      },
      "outputs": [],
      "source": [
        "#2a) Fix Graph, Vary Random Node Features and X. \n",
        "#2b) Fix Random Node Features, Vary Graph and X\n",
        "#2c) Fix X. Vary Random Node Features and Graph\n",
        "# In which case is data efficiency helped the most. What is the effect of X on the label\n",
        "# Does random node feature make sense?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcoFGtGQmitG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp5sYtAr6aDJ"
      },
      "source": [
        "##Experiment 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXTs95Y97Iho"
      },
      "outputs": [],
      "source": [
        "# Vary G, Random Node Features and X. \n",
        "# Compare data efficiency of MPNN compared to Standard MPNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzUnBGRUmiWa"
      },
      "outputs": [],
      "source": [
        "#GENERATE DATASET:\n",
        "\n",
        "n_nodes = 4\n",
        "p = 0.5\n",
        "input_nf, output_nf, hidden_nf, coords = 4, 1, 24, 3\n",
        "mu_x, sigma_x, mu_h, sigma_h = 0, 1, 1.5, 0.01\n",
        "\n",
        "#Dataset(Train-Val-Test)\n",
        "\n",
        "#Train:\n",
        "\n",
        "training_set_size = 10000\n",
        "batch_size = 100\n",
        "edges_tr, edge_attr_tr, tensor_edge_mask_tr, adj_list_tr = get_graph_batch(training_set_size, n_nodes, p)\n",
        "\n",
        "#Generate Node Features and Coordinates\n",
        "feat_tr = torch.normal(mean=mu_x,std=sigma_x, size=(training_set_size * n_nodes, input_nf))\n",
        "coord_tr = torch.normal(mean=mu_h,std=sigma_h,size=(training_set_size * n_nodes, coords))\n",
        "\n",
        "#Generate Labels: Training Set\n",
        "l_gen_tr = LabelGenerate(coord_tr, feat_tr, edges_tr, edge_attr_tr, training_set_size, n_nodes, adj_list_tr)\n",
        "x_tr, h_tr =  l_gen_tr.get_labels(type_f2 = 'distance')\n",
        "\n",
        "#Initializr NN:\n",
        "mpnn = MPNN(in_node_nf=input_nf, coords=coords, in_edge_nf=1, hidden_nf=hidden_nf, n_layers=2)\n",
        "egnn = EGNN(in_node_nf=input_nf, in_edge_nf=1, hidden_nf=hidden_nf, n_layers=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc75_sWKxQVw",
        "outputId": "0972766c-5bd8-4c63-e89a-9bf41b119aa4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7])"
            ]
          },
          "execution_count": 45,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges_tr[0][12:24]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8LhAtz8xTk4",
        "outputId": "c2f36c68-ad3d-4ad3-e2dc-427c606c5194"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5, 6, 7, 4, 6, 7, 4, 5, 7, 4, 5, 6])"
            ]
          },
          "execution_count": 46,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges_tr[1][12:24]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nPRvaGOxW3v",
        "outputId": "fd0562c6-52d4-4068-d358-041feed38654"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1],\n",
              "       [1, 0, 0, 0],\n",
              "       [1, 0, 0, 1],\n",
              "       [1, 0, 1, 0]], dtype=int64)"
            ]
          },
          "execution_count": 43,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adj_list_tr[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fg7SoWFxbob",
        "outputId": "72850e69-864b-413f-f351-8e0d17c86603"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.]])"
            ]
          },
          "execution_count": 44,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_edge_mask_tr[:12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aoj7wbJBIMBy",
        "outputId": "805eb187-0ec4-40f3-aba2-88ac90c55536"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "execution_count": 133,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size*n_nodes*(n_nodes-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "lfP32es_EK_x",
        "outputId": "a7964727-51ec-45f2-e8b8-778d69c813e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([6000])\n",
            "torch.Size([2000, 7])\n",
            "Epoch: 1, Iteration: 0, MPNN MSE: 1.6978, EGNN MSE: 0.1276\n",
            "torch.Size([6000])\n",
            "torch.Size([2000, 7])\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bbd05cf6a39b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mout_mpnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_edge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m#h_mpnn, x_mpnn = out_mpnn[:,0], out_mpnn[:,1:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mh_egnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_egnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0megnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_edge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-496fd5c00784>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edges, edge_attr, edge_mask, n_nodes)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_attr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gcl_%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gcl_%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-080fe34f795f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_mask, edge_attr, node_attr)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0medge_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0medge_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_feat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 2000 is out of bounds for dimension 0 with size 2000"
          ]
        }
      ],
      "source": [
        "#Train\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "max_epoch = 1000\n",
        "optimizer_mpnn = optim.SGD(mpnn.parameters(), lr=0.0001)\n",
        "loss_l1_mpnn = nn.L1Loss()\n",
        "optimizer_egnn = optim.SGD(egnn.parameters(), lr=0.0001)\n",
        "loss_l1_egnn = nn.L1Loss()\n",
        "batch_size = 500\n",
        "iteration = training_set_size // batch_size\n",
        "loss_mpnn_x_l = []\n",
        "loss_mpnn_h_l = []\n",
        "loss_egnn_x_l = []\n",
        "loss_egnn_h_l = []\n",
        "\n",
        "for i in range(max_epoch):\n",
        "  for iters in range(iteration):\n",
        "    #Each iteration is process #batch_size number of graphs\n",
        "\n",
        "    coord = coord_tr[iters*batch_size*n_nodes:(iters+1)*batch_size*n_nodes,:]\n",
        "    feat = feat_tr[iters*batch_size*n_nodes:(iters+1)*batch_size*n_nodes,:]\n",
        "    x_1 = x_tr[iters*batch_size*n_nodes:(iters+1)*batch_size*n_nodes,:]\n",
        "    h_1 = h_tr[iters*batch_size*n_nodes:(iters+1)*batch_size*n_nodes,:]\n",
        "    h_1 = torch.tensor(h_1)\n",
        "    edges_0 = edges_tr[0][iters*batch_size*n_nodes*(n_nodes-1):(iters+1)*batch_size*n_nodes*(n_nodes-1)]\n",
        "    edges_1 = edges_tr[1][iters*batch_size*n_nodes*(n_nodes-1):(iters+1)*batch_size*n_nodes*(n_nodes-1)]\n",
        "    edges = [edges_0, edges_1]\n",
        "    edge_attr = edge_attr_tr[iters*batch_size*n_nodes*(n_nodes-1):(iters+1)*batch_size*n_nodes*(n_nodes-1),:]\n",
        "    tensor_edge_mask = tensor_edge_mask_tr[iters*batch_size*n_nodes*(n_nodes-1):(iters+1)*batch_size*n_nodes*(n_nodes-1),:]\n",
        "    x = torch.cat([feat, coord], axis=1)\n",
        "    print(edges_0.shape)\n",
        "    print(x.shape)\n",
        "    out_mpnn = mpnn(x, edges, edge_attr, tensor_edge_mask, n_nodes)\n",
        "    #h_mpnn, x_mpnn = out_mpnn[:,0], out_mpnn[:,1:]\n",
        "    h_egnn, x_egnn = egnn(feat, coord, edges, edge_attr, tensor_edge_mask, n_nodes)\n",
        "\n",
        "    #out_egnn = torch.cat([x_egnn, h_egnn],axis=1)\n",
        "    #label = torch.cat([x_1, h_1], axis=1)\n",
        "    loss_mpnn_h = loss_l1_mpnn(out_mpnn[:,0].reshape(-1,1), h_1)\n",
        "    loss_egnn_h = loss_l1_egnn(h_egnn, h_1)\n",
        "    loss_mpnn_x = loss_l1_mpnn(out_mpnn[:,1:], x_1)\n",
        "    loss_egnn_x = loss_l1_egnn(x_egnn, x_1)\n",
        "    loss_mpnn = loss_mpnn_h + loss_mpnn_x\n",
        "    loss_egnn = loss_egnn_h + loss_egnn_x\n",
        "    loss_mpnn_x_l.append(loss_mpnn_x)\n",
        "    loss_mpnn_h_l.append(loss_mpnn_h)\n",
        "    loss_egnn_x_l.append(loss_egnn_x)\n",
        "    loss_egnn_h_l.append(loss_egnn_h)\n",
        "    loss_mpnn.backward()\n",
        "    loss_egnn.backward()\n",
        "    optimizer_mpnn.step()\n",
        "    optimizer_egnn.step()\n",
        "    if iters % 10 == 0:\n",
        "      print(\"Epoch: {}, Iteration: {}, MPNN MSE: {:.4f}, EGNN MSE: {:.4f}\".format((i+1), iters, loss_mpnn, loss_egnn))\n",
        "    if i % 50 == 1:\n",
        "      plt.figure()\n",
        "      plt.plot(loss_mpnn_x_l)\n",
        "      plt.title('MPNN X Loss')\n",
        "      plt.figure()\n",
        "      plt.plot(loss_egnn_x_l)\n",
        "      plt.title('EGNN X Loss')\n",
        "      plt.figure()\n",
        "      plt.plot(loss_mpnn_h_l)\n",
        "      plt.title('MPNN H Loss')\n",
        "      plt.figure()\n",
        "      plt.plot(loss_egnn_h_l)\n",
        "      plt.title('EGNN H Loss')\n",
        "      \n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iJRqwXhGK4N"
      },
      "outputs": [],
      "source": [
        "l = list(np.linspace(0,10))\n",
        "m = list(np.linspace(0,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03FKtzTZuw7c",
        "outputId": "6356b6d3-c060-4144-a8d0-1aae9d649587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([2000, 2000, 2000,  ..., 3999, 3999, 3999]), tensor([2001, 2002, 2003,  ..., 3996, 3997, 3998])]\n"
          ]
        }
      ],
      "source": [
        "print(edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "Vrvo1fYVGNj4",
        "outputId": "093061ef-f3e3-45ed-8b27-2edc4882f523"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb2f6cef110>]"
            ]
          },
          "execution_count": 124,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(l)\n",
        "plt.title('egnn h loss')\n",
        "plt.figure()\n",
        "plt.plot(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU712SjqGPBu",
        "outputId": "a2e96072-bf45-4bdb-eff8-f66f2ce6cf92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0]"
            ]
          },
          "execution_count": 117,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzQKGm2zGTFV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kMPnMgfJlp3S",
        "NJHfbRE369U7",
        "mz9gtZ1pYhRj",
        "CQIrtWmd1IQO",
        "lY_Dw6Aa6TKv",
        "eRDNWx6G6XCQ",
        "jp5sYtAr6aDJ"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}